{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452bd073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.133.0-py2.py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m670.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-auth<3.0.0,>=2.47.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Downloading proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform)\n",
      "  Downloading protobuf-6.33.3-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (25.0)\n",
      "Collecting google-cloud-storage<4.0.0,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_storage-3.7.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_bigquery-3.40.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_genai-1.57.0-py3-none-any.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3 in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: typing_extensions in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (4.15.0)\n",
      "Requirement already satisfied: docstring_parser<1 in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (0.17.0)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./venv/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform)\n",
      "  Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (3.11)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.16.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.6.3)\n",
      "Downloading google_cloud_aiplatform-1.133.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.40.0-py3-none-any.whl (261 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m261.3/261.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-3.7.0-py3-none-any.whl (303 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_genai-1.57.0-py3-none-any.whl (713 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.3-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: typing-inspection, tenacity, pydantic-core, pyasn1, protobuf, grpcio, google-crc32c, anyio, rsa, pydantic, pyasn1-modules, proto-plus, httpx, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-genai, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.1\n",
      "    Uninstalling pydantic_core-2.14.1:\n",
      "      Successfully uninstalled pydantic_core-2.14.1\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.7.1\n",
      "    Uninstalling anyio-3.7.1:\n",
      "      Successfully uninstalled anyio-3.7.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.0\n",
      "    Uninstalling pydantic-2.5.0:\n",
      "      Successfully uninstalled pydantic-2.5.0\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.104.1 requires anyio<4.0.0,>=3.7.1, but you have anyio 4.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anyio-4.12.1 google-api-core-2.29.0 google-auth-2.47.0 google-cloud-aiplatform-1.133.0 google-cloud-bigquery-3.40.0 google-cloud-core-2.5.0 google-cloud-resource-manager-1.15.0 google-cloud-storage-3.7.0 google-crc32c-1.8.0 google-genai-1.57.0 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 httpx-0.28.1 proto-plus-1.27.0 protobuf-6.33.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 rsa-4.9.1 tenacity-9.1.2 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4d3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ğŸ”‘ Setup Application Default Credentials for Vertex AI\n",
    "# Option 1: Use gcloud CLI (recommended for local development)\n",
    "# Run this in terminal: gcloud auth application-default login\n",
    "# Then restart the notebook\n",
    "\n",
    "# Option 2: Use service account JSON key file\n",
    "# Uncomment the line below and provide path to your service account JSON key\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/path/to/your/service-account-key.json\"\n",
    "\n",
    "PROJECT_ID = \"markazqa-36bbe\"\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2ab89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An API (Application Programming Interface) is a set of rules and specifications that software programs can follow to communicate with each other. Think of it as a menu in a restaurant: the menu lists the available dishes (functions) and how to order them (parameters), allowing you (a program) to get what you want from the kitchen (another program) without needing to know the inner workings of the kitchen itself. APIs enable developers to use pre-built functionality from other applications or services, saving time and effort and allowing for integration between different systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "# Load Gemini model - use stable version names WITHOUT @001\n",
    "# Latest stable models available in Vertex AI:\n",
    "# - gemini-2.0-flash (reliable, fast)\n",
    "# - gemini-2.0-flash-lite (faster, more cost-effective)\n",
    "# - gemini-2.0-pro (more powerful)\n",
    "# - gemini-3-flash (newest)\n",
    "\n",
    "model = GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(\n",
    "    \"Explain what an API is in one paragraph\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bb459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 failed: module 'vertexai.generative_models' has no attribute 'grpc_utils'\n",
      "\n",
      "âœ… Known Gemini models available in Vertex AI:\n",
      "  - gemini-1.5-pro\n",
      "  - gemini-1.5-flash\n",
      "  - gemini-1.5-pro-vision\n",
      "  - gemini-1.5-flash-vision\n",
      "  - gemini-2.0-flash-exp\n",
      "  - gemini-pro\n",
      "  - gemini-pro-vision\n",
      "\n",
      "ğŸ’¡ Try one of these models above in your code!\n"
     ]
    }
   ],
   "source": [
    "# Test with different Gemini models\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "print(\"âœ… Testing available Gemini models for Vertex AI...\\n\")\n",
    "\n",
    "# These are the stable model names for Vertex AI (as per Google Cloud docs)\n",
    "models_to_test = [\n",
    "    \"gemini-2.0-flash\",\n",
    "    \"gemini-2.0-flash-lite\",\n",
    "    \"gemini-2.0-pro\",\n",
    "    \"gemini-3-flash\",\n",
    "]\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        print(f\"ğŸ”„ Testing {model_name}...\", end=\" \")\n",
    "        model = GenerativeModel(model_name)\n",
    "        response = model.generate_content(\"Hi\")\n",
    "        print(\"âœ… SUCCESS!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed: {str(e)[:50]}...\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Use the working model name in cell 3 above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed603c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Vertex AI Batch Prediction for 50% Cost Savings\n",
      "\n",
      "Example JSONL format for batch requests:\n",
      "{\"request\": {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"What is 2+2?\"}]}]}}\n",
      "{\"request\": {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"What is the capital of France?\"}]}]}}\n",
      "\n",
      "ğŸ’¡ Batch API offers 50% discount on:\n",
      "  - Gemini 1.5 Flash\n",
      "  - Gemini 1.5 Pro\n",
      "  - Gemini 1.0 Pro\n",
      "\n",
      "âš ï¸ Note: Batch predictions require:\n",
      "  1. Google Cloud Storage bucket for input/output\n",
      "  2. Using aiplatform.BatchPredictionJob API\n",
      "  3. Asynchronous processing (takes minutes to hours)\n"
     ]
    }
   ],
   "source": [
    "# Example: Batch Processing with Vertex AI (50% cost savings!)\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from google.cloud import aiplatform\n",
    "import json\n",
    "\n",
    "print(\"ğŸ“¦ Vertex AI Batch Prediction for 50% Cost Savings\\n\")\n",
    "\n",
    "# Batch processing uses the Vertex AI Batch Prediction API\n",
    "# Steps:\n",
    "# 1. Prepare requests as JSONL file\n",
    "# 2. Upload to Google Cloud Storage (GCS)\n",
    "# 3. Create batch prediction job\n",
    "# 4. Retrieve results from GCS when complete\n",
    "\n",
    "# Example request format for JSONL file:\n",
    "example_requests = [\n",
    "    {\n",
    "        \"request\": {\n",
    "            \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"What is 2+2?\"}]}]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"request\": {\n",
    "            \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"What is the capital of France?\"}]}]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Example JSONL format for batch requests:\")\n",
    "for req in example_requests:\n",
    "    print(json.dumps(req))\n",
    "\n",
    "print(\"\\nğŸ’¡ Batch API offers 50% discount on:\")\n",
    "print(\"  - Gemini 1.5 Flash\")\n",
    "print(\"  - Gemini 1.5 Pro\")\n",
    "print(\"  - Gemini 1.0 Pro\")\n",
    "\n",
    "print(\"\\nâš ï¸ Note: Batch predictions require:\")\n",
    "print(\"  1. Google Cloud Storage bucket for input/output\")\n",
    "print(\"  2. Using aiplatform.BatchPredictionJob API\")\n",
    "print(\"  3. Asynchronous processing (takes minutes to hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API connection successful\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure with your unrestricted GCP API key\n",
    "genai.configure(api_key=\"AIzaSyAJMs2_tcbyOp3GAkCypWA30T02SZC14E4\")\n",
    "\n",
    "# Test with Gemini API\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "response = model.generate_content(\"Say 'API connection successful'\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832830ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad-jan/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_7741/3849617510.py:1: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m genai.configure(api_key=\u001b[33m\"\u001b[39m\u001b[33mAIzaSyAJMs2_tcbyOp3GAkCypWA30T02SZC14E4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# List all available models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModel: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m  Display Name: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/generativeai/models.py:204\u001b[39m, in \u001b[36mlist_models\u001b[39m\u001b[34m(page_size, client, request_options)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    202\u001b[39m     client = get_default_model_client()\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    205\u001b[39m     model = \u001b[38;5;28mtype\u001b[39m(model).to_dict(model)\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m model_types.Model(**model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/model_service/client.py:923\u001b[39m, in \u001b[36mModelServiceClient.list_models\u001b[39m\u001b[34m(self, request, page_size, page_token, retry, timeout, metadata)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    922\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# This method is paged; wrap the response in a pager, which provides\u001b[39;00m\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m# an `__iter__` convenience method.\u001b[39;00m\n\u001b[32m    932\u001b[39m response = pagers.ListModelsPager(\n\u001b[32m    933\u001b[39m     method=rpc,\n\u001b[32m    934\u001b[39m     request=request,\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m     metadata=metadata,\n\u001b[32m    939\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Markaz/weight estimation/venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mInvalidArgument\u001b[39m: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAJMs2_tcbyOp3GAkCypWA30T02SZC14E4\")\n",
    "\n",
    "# List all available models\n",
    "for model in genai.list_models():\n",
    "    print(f\"Model: {model.name}\")\n",
    "    print(f\"  Display Name: {model.display_name}\")\n",
    "    print(f\"  Input tokens: {model.input_token_limit}\")\n",
    "    print(f\"  Supported methods: {model.supported_generation_methods}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f762b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
