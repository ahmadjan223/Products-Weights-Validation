{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452bd073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.133.0-py2.py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m670.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-auth<3.0.0,>=2.47.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Downloading proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform)\n",
      "  Downloading protobuf-6.33.3-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (25.0)\n",
      "Collecting google-cloud-storage<4.0.0,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_storage-3.7.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_bigquery-3.40.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_genai-1.57.0-py3-none-any.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3 in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: typing_extensions in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (4.15.0)\n",
      "Requirement already satisfied: docstring_parser<1 in ./venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (0.17.0)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./venv/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform)\n",
      "  Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (3.11)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.16.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.6.3)\n",
      "Downloading google_cloud_aiplatform-1.133.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.40.0-py3-none-any.whl (261 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m261.3/261.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-3.7.0-py3-none-any.whl (303 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_genai-1.57.0-py3-none-any.whl (713 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.3-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: typing-inspection, tenacity, pydantic-core, pyasn1, protobuf, grpcio, google-crc32c, anyio, rsa, pydantic, pyasn1-modules, proto-plus, httpx, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-genai, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.1\n",
      "    Uninstalling pydantic_core-2.14.1:\n",
      "      Successfully uninstalled pydantic_core-2.14.1\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.7.1\n",
      "    Uninstalling anyio-3.7.1:\n",
      "      Successfully uninstalled anyio-3.7.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.0\n",
      "    Uninstalling pydantic-2.5.0:\n",
      "      Successfully uninstalled pydantic-2.5.0\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.104.1 requires anyio<4.0.0,>=3.7.1, but you have anyio 4.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anyio-4.12.1 google-api-core-2.29.0 google-auth-2.47.0 google-cloud-aiplatform-1.133.0 google-cloud-bigquery-3.40.0 google-cloud-core-2.5.0 google-cloud-resource-manager-1.15.0 google-cloud-storage-3.7.0 google-crc32c-1.8.0 google-genai-1.57.0 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 httpx-0.28.1 proto-plus-1.27.0 protobuf-6.33.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 rsa-4.9.1 tenacity-9.1.2 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4d3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ğŸ”‘ Setup Application Default Credentials for Vertex AI\n",
    "# Option 1: Use gcloud CLI (recommended for local development)\n",
    "# Run this in terminal: gcloud auth application-default login\n",
    "# Then restart the notebook\n",
    "\n",
    "# Option 2: Use service account JSON key file\n",
    "# Uncomment the line below and provide path to your service account JSON key\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/path/to/your/service-account-key.json\"\n",
    "\n",
    "PROJECT_ID = \"markazqa-36bbe\"\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2ab89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An API (Application Programming Interface) is a set of rules and specifications that software programs can follow to communicate with each other. Think of it as a menu in a restaurant: the menu lists the available dishes (functions) and how to order them (parameters), allowing you (a program) to get what you want from the kitchen (another program) without needing to know the inner workings of the kitchen itself. APIs enable developers to use pre-built functionality from other applications or services, saving time and effort and allowing for integration between different systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "# Load Gemini model - use stable version names WITHOUT @001\n",
    "# Latest stable models available in Vertex AI:\n",
    "# - gemini-2.0-flash (reliable, fast)\n",
    "# - gemini-2.0-flash-lite (faster, more cost-effective)\n",
    "# - gemini-2.0-pro (more powerful)\n",
    "# - gemini-3-flash (newest)\n",
    "\n",
    "model = GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(\n",
    "    \"Explain what an API is in one paragraph\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f762b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make decisions or predictions, mimicking human intelligence.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399093b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini models:\n",
      "\n",
      "Model: models/embedding-gecko-001\n",
      "  Display name: Embedding Gecko\n",
      "  Description: Obtain a distributed representation of a text.\n",
      "\n",
      "Model: models/gemini-2.5-flash\n",
      "  Display name: Gemini 2.5 Flash\n",
      "  Description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\n",
      "\n",
      "Model: models/gemini-2.5-pro\n",
      "  Display name: Gemini 2.5 Pro\n",
      "  Description: Stable release (June 17th, 2025) of Gemini 2.5 Pro\n",
      "\n",
      "Model: models/gemini-2.0-flash-exp\n",
      "  Display name: Gemini 2.0 Flash Experimental\n",
      "  Description: Gemini 2.0 Flash Experimental\n",
      "\n",
      "Model: models/gemini-2.0-flash\n",
      "  Display name: Gemini 2.0 Flash\n",
      "  Description: Gemini 2.0 Flash\n",
      "\n",
      "Model: models/gemini-2.0-flash-001\n",
      "  Display name: Gemini 2.0 Flash 001\n",
      "  Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "\n",
      "Model: models/gemini-2.0-flash-exp-image-generation\n",
      "  Display name: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "  Description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite-001\n",
      "  Display name: Gemini 2.0 Flash-Lite 001\n",
      "  Description: Stable version of Gemini 2.0 Flash-Lite\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite\n",
      "  Display name: Gemini 2.0 Flash-Lite\n",
      "  Description: Gemini 2.0 Flash-Lite\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite-preview-02-05\n",
      "  Display name: Gemini 2.0 Flash-Lite Preview 02-05\n",
      "  Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "\n",
      "Model: models/gemini-2.0-flash-lite-preview\n",
      "  Display name: Gemini 2.0 Flash-Lite Preview\n",
      "  Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "\n",
      "Model: models/gemini-exp-1206\n",
      "  Display name: Gemini Experimental 1206\n",
      "  Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "\n",
      "Model: models/gemini-2.5-flash-preview-tts\n",
      "  Display name: Gemini 2.5 Flash Preview TTS\n",
      "  Description: Gemini 2.5 Flash Preview TTS\n",
      "\n",
      "Model: models/gemini-2.5-pro-preview-tts\n",
      "  Display name: Gemini 2.5 Pro Preview TTS\n",
      "  Description: Gemini 2.5 Pro Preview TTS\n",
      "\n",
      "Model: models/gemma-3-1b-it\n",
      "  Display name: Gemma 3 1B\n",
      "  Description: None\n",
      "\n",
      "Model: models/gemma-3-4b-it\n",
      "  Display name: Gemma 3 4B\n",
      "  Description: None\n",
      "\n",
      "Model: models/gemma-3-12b-it\n",
      "  Display name: Gemma 3 12B\n",
      "  Description: None\n",
      "\n",
      "Model: models/gemma-3-27b-it\n",
      "  Display name: Gemma 3 27B\n",
      "  Description: None\n",
      "\n",
      "Model: models/gemma-3n-e4b-it\n",
      "  Display name: Gemma 3n E4B\n",
      "  Description: None\n",
      "\n",
      "Model: models/gemma-3n-e2b-it\n",
      "  Display name: Gemma 3n E2B\n",
      "  Description: None\n",
      "\n",
      "Model: models/gemini-flash-latest\n",
      "  Display name: Gemini Flash Latest\n",
      "  Description: Latest release of Gemini Flash\n",
      "\n",
      "Model: models/gemini-flash-lite-latest\n",
      "  Display name: Gemini Flash-Lite Latest\n",
      "  Description: Latest release of Gemini Flash-Lite\n",
      "\n",
      "Model: models/gemini-pro-latest\n",
      "  Display name: Gemini Pro Latest\n",
      "  Description: Latest release of Gemini Pro\n",
      "\n",
      "Model: models/gemini-2.5-flash-lite\n",
      "  Display name: Gemini 2.5 Flash-Lite\n",
      "  Description: Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\n",
      "\n",
      "Model: models/gemini-2.5-flash-image-preview\n",
      "  Display name: Nano Banana\n",
      "  Description: Gemini 2.5 Flash Preview Image\n",
      "\n",
      "Model: models/gemini-2.5-flash-image\n",
      "  Display name: Nano Banana\n",
      "  Description: Gemini 2.5 Flash Preview Image\n",
      "\n",
      "Model: models/gemini-2.5-flash-preview-09-2025\n",
      "  Display name: Gemini 2.5 Flash Preview Sep 2025\n",
      "  Description: Gemini 2.5 Flash Preview Sep 2025\n",
      "\n",
      "Model: models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  Display name: Gemini 2.5 Flash-Lite Preview Sep 2025\n",
      "  Description: Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite\n",
      "\n",
      "Model: models/gemini-3-pro-preview\n",
      "  Display name: Gemini 3 Pro Preview\n",
      "  Description: Gemini 3 Pro Preview\n",
      "\n",
      "Model: models/gemini-3-flash-preview\n",
      "  Display name: Gemini 3 Flash Preview\n",
      "  Description: Gemini 3 Flash Preview\n",
      "\n",
      "Model: models/gemini-3-pro-image-preview\n",
      "  Display name: Nano Banana Pro\n",
      "  Description: Gemini 3 Pro Image Preview\n",
      "\n",
      "Model: models/nano-banana-pro-preview\n",
      "  Display name: Nano Banana Pro\n",
      "  Description: Gemini 3 Pro Image Preview\n",
      "\n",
      "Model: models/gemini-robotics-er-1.5-preview\n",
      "  Display name: Gemini Robotics-ER 1.5 Preview\n",
      "  Description: Gemini Robotics-ER 1.5 Preview\n",
      "\n",
      "Model: models/gemini-2.5-computer-use-preview-10-2025\n",
      "  Display name: Gemini 2.5 Computer Use Preview 10-2025\n",
      "  Description: Gemini 2.5 Computer Use Preview 10-2025\n",
      "\n",
      "Model: models/deep-research-pro-preview-12-2025\n",
      "  Display name: Deep Research Pro Preview (Dec-12-2025)\n",
      "  Description: Preview release (December 12th, 2025) of Deep Research Pro\n",
      "\n",
      "Model: models/embedding-001\n",
      "  Display name: Embedding 001\n",
      "  Description: Obtain a distributed representation of a text.\n",
      "\n",
      "Model: models/text-embedding-004\n",
      "  Display name: Text Embedding 004\n",
      "  Description: Obtain a distributed representation of a text.\n",
      "\n",
      "Model: models/gemini-embedding-exp-03-07\n",
      "  Display name: Gemini Embedding Experimental 03-07\n",
      "  Description: Obtain a distributed representation of a text.\n",
      "\n",
      "Model: models/gemini-embedding-exp\n",
      "  Display name: Gemini Embedding Experimental\n",
      "  Description: Obtain a distributed representation of a text.\n",
      "\n",
      "Model: models/gemini-embedding-001\n",
      "  Display name: Gemini Embedding 001\n",
      "  Description: Obtain a distributed representation of a text.\n",
      "\n",
      "Model: models/aqa\n",
      "  Display name: Model that performs Attributed Question Answering.\n",
      "  Description: Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "\n",
      "Model: models/imagen-4.0-generate-preview-06-06\n",
      "  Display name: Imagen 4 (Preview)\n",
      "  Description: Vertex served Imagen 4.0 model\n",
      "\n",
      "Model: models/imagen-4.0-ultra-generate-preview-06-06\n",
      "  Display name: Imagen 4 Ultra (Preview)\n",
      "  Description: Vertex served Imagen 4.0 ultra model\n",
      "\n",
      "Model: models/imagen-4.0-generate-001\n",
      "  Display name: Imagen 4\n",
      "  Description: Vertex served Imagen 4.0 model\n",
      "\n",
      "Model: models/imagen-4.0-ultra-generate-001\n",
      "  Display name: Imagen 4 Ultra\n",
      "  Description: Vertex served Imagen 4.0 ultra model\n",
      "\n",
      "Model: models/imagen-4.0-fast-generate-001\n",
      "  Display name: Imagen 4 Fast\n",
      "  Description: Vertex served Imagen 4.0 Fast model\n",
      "\n",
      "Model: models/veo-2.0-generate-001\n",
      "  Display name: Veo 2\n",
      "  Description: Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.\n",
      "\n",
      "Model: models/veo-3.0-generate-001\n",
      "  Display name: Veo 3\n",
      "  Description: Veo 3\n",
      "\n",
      "Model: models/veo-3.0-fast-generate-001\n",
      "  Display name: Veo 3 fast\n",
      "  Description: Veo 3 fast\n",
      "\n",
      "Model: models/veo-3.1-generate-preview\n",
      "  Display name: Veo 3.1\n",
      "  Description: Veo 3.1\n",
      "\n",
      "Model: models/veo-3.1-fast-generate-preview\n",
      "  Display name: Veo 3.1 fast\n",
      "  Description: Veo 3.1 fast\n",
      "\n",
      "Model: models/gemini-2.5-flash-native-audio-latest\n",
      "  Display name: Gemini 2.5 Flash Native Audio Latest\n",
      "  Description: Latest release of Gemini 2.5 Flash Native Audio\n",
      "\n",
      "Model: models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "  Display name: Gemini 2.5 Flash Native Audio Preview 09-2025\n",
      "  Description: Gemini 2.5 Flash Native Audio Preview 09-2025\n",
      "\n",
      "Model: models/gemini-2.5-flash-native-audio-preview-12-2025\n",
      "  Display name: Gemini 2.5 Flash Native Audio Preview 12-2025\n",
      "  Description: Gemini 2.5 Flash Native Audio Preview 12-2025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# List all available models\n",
    "print(\"Available Gemini models:\\n\")\n",
    "for model in client.models.list():\n",
    "    print(f\"Model: {model.name}\")\n",
    "    print(f\"  Display name: {model.display_name}\")\n",
    "    print(f\"  Description: {model.description}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460cda47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created batch job: batches/kfrhexhyiypuv14901v314a6fkn9f6mju5ks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# A list of dictionaries, where each is a GenerateContentRequest\n",
    "inline_requests = [\n",
    "    {\n",
    "        'contents': [{\n",
    "            'parts': [{'text': 'Tell me a one-sentence joke.'}],\n",
    "            'role': 'user'\n",
    "        }]\n",
    "    },\n",
    "    {\n",
    "        'contents': [{\n",
    "            'parts': [{'text': 'Why is the sky blue?'}],\n",
    "            'role': 'user'\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "inline_batch_job = client.batches.create(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    src=inline_requests,\n",
    "    config={\n",
    "        'display_name': \"inlined-requests-job-1\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Created batch job: {inline_batch_job.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a00986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polling status for job: batches/kfrhexhyiypuv14901v314a6fkn9f6mju5ks\n",
      "Current state: JOB_STATE_PENDING\n",
      "Current state: JOB_STATE_PENDING\n",
      "Current state: JOB_STATE_PENDING\n",
      "Current state: JOB_STATE_PENDING\n",
      "Current state: JOB_STATE_PENDING\n",
      "Job finished with state: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Use the name of the job you want to check\n",
    "# e.g., inline_batch_job.name from the previous step\n",
    "job_name = \"batches/kfrhexhyiypuv14901v314a6fkn9f6mju5ks\"  # (e.g. 'batches/your-batch-id')\n",
    "batch_job = client.batches.get(name=job_name)\n",
    "\n",
    "completed_states = set([\n",
    "    'JOB_STATE_SUCCEEDED',\n",
    "    'JOB_STATE_FAILED',\n",
    "    'JOB_STATE_CANCELLED',\n",
    "    'JOB_STATE_EXPIRED',\n",
    "])\n",
    "\n",
    "print(f\"Polling status for job: {job_name}\")\n",
    "batch_job = client.batches.get(name=job_name) # Initial get\n",
    "while batch_job.state.name not in completed_states:\n",
    "  print(f\"Current state: {batch_job.state.name}\")\n",
    "  time.sleep(30) # Wait for 30 seconds before polling again\n",
    "  batch_job = client.batches.get(name=job_name)\n",
    "\n",
    "print(f\"Job finished with state: {batch_job.state.name}\")\n",
    "if batch_job.state.name == 'JOB_STATE_FAILED':\n",
    "    print(f\"Error: {batch_job.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffb10c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are inline:\n",
      "Response 1:\n",
      "What do you call a fake noodle? An impasta!\n",
      "Response 2:\n",
      "The sky is blue primarily due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\n",
      "\n",
      "1.  **Sunlight is White Light:** Sunlight, which appears white to us, is actually made up of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, violet). Each of these colors has a different wavelength. Blue and violet light have shorter wavelengths, while red and orange light have longer wavelengths.\n",
      "\n",
      "2.  **Earth's Atmosphere:** Our atmosphere is composed mainly of tiny gas molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "3.  **Rayleigh Scattering:** When sunlight enters the Earth's atmosphere, it collides with these tiny gas molecules.\n",
      "    *   **Short wavelengths (like blue and violet) are scattered much more effectively** than longer wavelengths (like red and yellow). This is because the gas molecules are much smaller than the wavelengths of visible light, and this type of scattering is highly wavelength-dependent. Blue light is scattered about 10 times more effectively than red light.\n",
      "    *   Imagine it like tiny obstacles: the shorter, choppier blue waves are more likely to hit and bounce off the tiny molecules than the long, sweeping red waves.\n",
      "\n",
      "4.  **Why We See Blue:** Because blue light is scattered in all directions by the gas molecules throughout the atmosphere, it appears to come to us from every part of the sky. When you look up, you're seeing this scattered blue light.\n",
      "\n",
      "5.  **Why Not Violet?** Violet light has an even shorter wavelength than blue light and is scattered even more. However, there are two main reasons why we don't see a violet sky:\n",
      "    *   **The Sun emits less violet light** than blue light.\n",
      "    *   **Our eyes are more sensitive to blue light** than to violet light. The combination of these factors makes blue the dominant color we perceive.\n",
      "\n",
      "**In summary:** The tiny molecules in Earth's atmosphere prefer to scatter the shorter, bluer wavelengths of sunlight. This scattered blue light reaches our eyes from all directions, making the sky appear blue.\n",
      "\n",
      "**Bonus Fact: Why Sunsets are Red/Orange**\n",
      "When the sun is low on the horizon (sunrise or sunset), its light has to travel through a much greater amount of atmosphere to reach your eyes. By the time it gets to you, most of the blue and violet light has been scattered away, leaving primarily the longer wavelengths of red, orange, and yellow light to pass through directly, creating those beautiful colorful skies.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Use the name of the job you want to check\n",
    "# e.g., inline_batch_job.name from the previous step\n",
    "job_name = \"batches/kfrhexhyiypuv14901v314a6fkn9f6mju5ks\"\n",
    "batch_job = client.batches.get(name=job_name)\n",
    "\n",
    "if batch_job.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "\n",
    "    # If batch job was created with a file\n",
    "    if batch_job.dest and batch_job.dest.file_name:\n",
    "        # Results are in a file\n",
    "        result_file_name = batch_job.dest.file_name\n",
    "        print(f\"Results are in file: {result_file_name}\")\n",
    "\n",
    "        print(\"Downloading result file content...\")\n",
    "        file_content = client.files.download(file=result_file_name)\n",
    "        # Process file_content (bytes) as needed\n",
    "        print(file_content.decode('utf-8'))\n",
    "\n",
    "    # If batch job was created with inline request\n",
    "    # (for embeddings, use batch_job.dest.inlined_embed_content_responses)\n",
    "    elif batch_job.dest and batch_job.dest.inlined_responses:\n",
    "        # Results are inline\n",
    "        print(\"Results are inline:\")\n",
    "        for i, inline_response in enumerate(batch_job.dest.inlined_responses):\n",
    "            print(f\"Response {i+1}:\")\n",
    "            if inline_response.response:\n",
    "                # Accessing response, structure may vary.\n",
    "                try:\n",
    "                    print(inline_response.response.text)\n",
    "                except AttributeError:\n",
    "                    print(inline_response.response) # Fallback\n",
    "            elif inline_response.error:\n",
    "                print(f\"Error: {inline_response.error}\")\n",
    "    else:\n",
    "        print(\"No results found (neither file nor inline).\")\n",
    "else:\n",
    "    print(f\"Job did not succeed. Final state: {batch_job.state.name}\")\n",
    "    if batch_job.error:\n",
    "        print(f\"Error: {batch_job.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9f032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
